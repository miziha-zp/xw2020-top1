{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import entropy\n",
    "import gc\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "pd.set_option('display.max_columns', 600)\n",
    "pd.set_option('display.max_rows', 600)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path  = '../data/final_data/'\n",
    "data_train = pd.read_csv(root_path+'sensor_train_final.csv')\n",
    "data_test = pd.read_csv(root_path+'sensor_test_final.csv')\n",
    "sub = pd.read_csv(root_path+'submit_example.csv')\n",
    "y = data_train.groupby('fragment_id')['behavior_id'].min()\n",
    "data_test['fragment_id'] += 100000\n",
    "label = 'behavior_id'\n",
    "data = pd.concat([data_train, data_test], sort=False,ignore_index=True)\n",
    "df = data.drop_duplicates(subset=['fragment_id']).reset_index(drop=True)[['fragment_id', 'behavior_id']]\n",
    "df[\"count\"] = data.groupby(\"fragment_id\")[\"time_point\"].count()\n",
    "\n",
    "featureList = [\"count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31000, 20)\n"
     ]
    }
   ],
   "source": [
    "# LGB model\n",
    "import joblib\n",
    "lgboof = joblib.load(\"LGB_OOF.pkl\")\n",
    "oof = lgboof[\"oof\"]\n",
    "preds = lgboof[\"test\"]\n",
    "\n",
    "stack_array = np.concatenate([oof,preds],axis=0)\n",
    "print(stack_array.shape)\n",
    "for i in range(20):\n",
    "    df[\"lgb_\"+str(i)] = stack_array[:,i]\n",
    "featureList += [\"lgb_\"+str(i)for i in range(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31000, 20)\n"
     ]
    }
   ],
   "source": [
    "# LSTM model\n",
    "import joblib \n",
    "lstmoof = joblib.load(\"LSTM8370.83753_dict.pkl\")\n",
    "oof = lstmoof[\"oof\"]\n",
    "preds = lstmoof[\"test\"]\n",
    "\n",
    "stack_array = np.concatenate([oof,preds],axis=0)\n",
    "print(stack_array.shape)\n",
    "for i in range(20):\n",
    "    df[\"lstm_\"+str(i)] = stack_array[:,i]\n",
    "featureList += [\"lstm_\"+str(i)for i in range(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31000, 20)\n"
     ]
    }
   ],
   "source": [
    "# CNN\n",
    "import joblib \n",
    "\n",
    "cnnoof = joblib.load(\"all_stragety_lcy1_0.84695_dict.pkl\")\n",
    "oof = cnnoof[\"oof\"]\n",
    "preds = cnnoof[\"test\"]\n",
    "\n",
    "stack_array = np.concatenate([oof,preds],axis=0)\n",
    "print(stack_array.shape)\n",
    "for i in range(20):\n",
    "    df[\"CNN_\"+str(i)] = stack_array[:,i]\n",
    "featureList += [\"CNN_\"+str(i)for i in range(20)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "['count', 'lgb_0', 'lgb_1', 'lgb_2', 'lgb_3', 'lgb_4', 'lgb_5', 'lgb_6', 'lgb_7', 'lgb_8', 'lgb_9', 'lgb_10', 'lgb_11', 'lgb_12', 'lgb_13', 'lgb_14', 'lgb_15', 'lgb_16', 'lgb_17', 'lgb_18', 'lgb_19', 'lstm_0', 'lstm_1', 'lstm_2', 'lstm_3', 'lstm_4', 'lstm_5', 'lstm_6', 'lstm_7', 'lstm_8', 'lstm_9', 'lstm_10', 'lstm_11', 'lstm_12', 'lstm_13', 'lstm_14', 'lstm_15', 'lstm_16', 'lstm_17', 'lstm_18', 'lstm_19', 'CNN_0', 'CNN_1', 'CNN_2', 'CNN_3', 'CNN_4', 'CNN_5', 'CNN_6', 'CNN_7', 'CNN_8', 'CNN_9', 'CNN_10', 'CNN_11', 'CNN_12', 'CNN_13', 'CNN_14', 'CNN_15', 'CNN_16', 'CNN_17', 'CNN_18', 'CNN_19']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.fillna(0)\n",
    "df.loc[:15000,\"istrain\"] = 1\n",
    "df.loc[15000:,\"istrain\"] = 0\n",
    "\n",
    "train_df = df[df[\"istrain\"]==1].reset_index(drop=True)\n",
    "test_df = df[df[\"istrain\"]==0].reset_index(drop=True)\n",
    "\n",
    "drop_feat = [\"istrain\"]\n",
    "used_feat = [f for f in train_df.columns if f not in (['fragment_id', label] + drop_feat)]\n",
    "print(len(used_feat))\n",
    "print(used_feat)\n",
    "\n",
    "train_x = train_df[used_feat]\n",
    "train_y = train_df[label]\n",
    "test_x = test_df[used_feat]\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0606667\tvalid_1's multi_error: 0.114333\n",
      "[40]\ttraining's multi_error: 0.0246667\tvalid_1's multi_error: 0.117333\n",
      "[60]\ttraining's multi_error: 0.006\tvalid_1's multi_error: 0.116\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's multi_error: 0.0585833\tvalid_1's multi_error: 0.113667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2063"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0603333\tvalid_1's multi_error: 0.127667\n",
      "[40]\ttraining's multi_error: 0.0236667\tvalid_1's multi_error: 0.126\n",
      "[60]\ttraining's multi_error: 0.00616667\tvalid_1's multi_error: 0.127667\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's multi_error: 0.0455833\tvalid_1's multi_error: 0.124333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "373"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0605833\tvalid_1's multi_error: 0.127667\n",
      "[40]\ttraining's multi_error: 0.0253333\tvalid_1's multi_error: 0.129333\n",
      "[60]\ttraining's multi_error: 0.00666667\tvalid_1's multi_error: 0.129667\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's multi_error: 0.05125\tvalid_1's multi_error: 0.125667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6262"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0589167\tvalid_1's multi_error: 0.138\n",
      "[40]\ttraining's multi_error: 0.0231667\tvalid_1's multi_error: 0.138\n",
      "[60]\ttraining's multi_error: 0.00625\tvalid_1's multi_error: 0.135667\n",
      "[80]\ttraining's multi_error: 0.00133333\tvalid_1's multi_error: 0.137667\n",
      "[100]\ttraining's multi_error: 0.000666667\tvalid_1's multi_error: 0.138\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's multi_error: 0.00625\tvalid_1's multi_error: 0.135667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.058\tvalid_1's multi_error: 0.129667\n",
      "[40]\ttraining's multi_error: 0.02325\tvalid_1's multi_error: 0.130333\n",
      "[60]\ttraining's multi_error: 0.00608333\tvalid_1's multi_error: 0.130333\n",
      "[80]\ttraining's multi_error: 0.00116667\tvalid_1's multi_error: 0.128\n",
      "[100]\ttraining's multi_error: 0.000416667\tvalid_1's multi_error: 0.129\n",
      "[120]\ttraining's multi_error: 0.000333333\tvalid_1's multi_error: 0.13\n",
      "[140]\ttraining's multi_error: 0.000333333\tvalid_1's multi_error: 0.128333\n",
      "Early stopping, best iteration is:\n",
      "[96]\ttraining's multi_error: 0.000416667\tvalid_1's multi_error: 0.126\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "228"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.05975\tvalid_1's multi_error: 0.130667\n",
      "[40]\ttraining's multi_error: 0.0233333\tvalid_1's multi_error: 0.131\n",
      "[60]\ttraining's multi_error: 0.00608333\tvalid_1's multi_error: 0.130333\n",
      "[80]\ttraining's multi_error: 0.00183333\tvalid_1's multi_error: 0.130667\n",
      "[100]\ttraining's multi_error: 0.00075\tvalid_1's multi_error: 0.130667\n",
      "[120]\ttraining's multi_error: 0.00025\tvalid_1's multi_error: 0.129\n",
      "Early stopping, best iteration is:\n",
      "[88]\ttraining's multi_error: 0.00108333\tvalid_1's multi_error: 0.128667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0594167\tvalid_1's multi_error: 0.130333\n",
      "[40]\ttraining's multi_error: 0.0243333\tvalid_1's multi_error: 0.126333\n",
      "[60]\ttraining's multi_error: 0.00683333\tvalid_1's multi_error: 0.126333\n",
      "[80]\ttraining's multi_error: 0.00191667\tvalid_1's multi_error: 0.125333\n",
      "[100]\ttraining's multi_error: 0.000583333\tvalid_1's multi_error: 0.126667\n",
      "[120]\ttraining's multi_error: 0.0005\tvalid_1's multi_error: 0.127333\n",
      "Early stopping, best iteration is:\n",
      "[80]\ttraining's multi_error: 0.00191667\tvalid_1's multi_error: 0.125333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0595\tvalid_1's multi_error: 0.119\n",
      "[40]\ttraining's multi_error: 0.0244167\tvalid_1's multi_error: 0.119333\n",
      "[60]\ttraining's multi_error: 0.00591667\tvalid_1's multi_error: 0.119\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's multi_error: 0.0664167\tvalid_1's multi_error: 0.116333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0608333\tvalid_1's multi_error: 0.125333\n",
      "[40]\ttraining's multi_error: 0.025\tvalid_1's multi_error: 0.126333\n",
      "[60]\ttraining's multi_error: 0.00516667\tvalid_1's multi_error: 0.123667\n",
      "[80]\ttraining's multi_error: 0.00116667\tvalid_1's multi_error: 0.122667\n",
      "[100]\ttraining's multi_error: 0.000166667\tvalid_1's multi_error: 0.123333\n",
      "[120]\ttraining's multi_error: 8.33333e-05\tvalid_1's multi_error: 0.121667\n",
      "[140]\ttraining's multi_error: 8.33333e-05\tvalid_1's multi_error: 0.123\n",
      "[160]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.122667\n",
      "Early stopping, best iteration is:\n",
      "[128]\ttraining's multi_error: 8.33333e-05\tvalid_1's multi_error: 0.121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "356"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0584167\tvalid_1's multi_error: 0.133\n",
      "[40]\ttraining's multi_error: 0.0264167\tvalid_1's multi_error: 0.134\n",
      "[60]\ttraining's multi_error: 0.00583333\tvalid_1's multi_error: 0.135\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's multi_error: 0.064\tvalid_1's multi_error: 0.132667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.06\tvalid_1's multi_error: 0.128\n",
      "[40]\ttraining's multi_error: 0.0239167\tvalid_1's multi_error: 0.132333\n",
      "[60]\ttraining's multi_error: 0.00583333\tvalid_1's multi_error: 0.131\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's multi_error: 0.0760833\tvalid_1's multi_error: 0.125667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0605\tvalid_1's multi_error: 0.122667\n",
      "[40]\ttraining's multi_error: 0.02575\tvalid_1's multi_error: 0.124\n",
      "[60]\ttraining's multi_error: 0.00666667\tvalid_1's multi_error: 0.123667\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's multi_error: 0.0731667\tvalid_1's multi_error: 0.121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "312"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0595\tvalid_1's multi_error: 0.131333\n",
      "[40]\ttraining's multi_error: 0.0238333\tvalid_1's multi_error: 0.133333\n",
      "[60]\ttraining's multi_error: 0.00616667\tvalid_1's multi_error: 0.135333\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's multi_error: 0.0696667\tvalid_1's multi_error: 0.128333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "316"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.05925\tvalid_1's multi_error: 0.122333\n",
      "[40]\ttraining's multi_error: 0.025\tvalid_1's multi_error: 0.122667\n",
      "[60]\ttraining's multi_error: 0.00575\tvalid_1's multi_error: 0.122\n",
      "[80]\ttraining's multi_error: 0.00191667\tvalid_1's multi_error: 0.123\n",
      "[100]\ttraining's multi_error: 0.00075\tvalid_1's multi_error: 0.121667\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's multi_error: 0.0055\tvalid_1's multi_error: 0.120333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0595833\tvalid_1's multi_error: 0.134333\n",
      "[40]\ttraining's multi_error: 0.0264167\tvalid_1's multi_error: 0.129667\n",
      "[60]\ttraining's multi_error: 0.00691667\tvalid_1's multi_error: 0.127667\n",
      "[80]\ttraining's multi_error: 0.00175\tvalid_1's multi_error: 0.128333\n",
      "[100]\ttraining's multi_error: 0.00075\tvalid_1's multi_error: 0.129333\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's multi_error: 0.01075\tvalid_1's multi_error: 0.126667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0600833\tvalid_1's multi_error: 0.126\n",
      "[40]\ttraining's multi_error: 0.0251667\tvalid_1's multi_error: 0.126333\n",
      "[60]\ttraining's multi_error: 0.00575\tvalid_1's multi_error: 0.128667\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's multi_error: 0.0615\tvalid_1's multi_error: 0.125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "332"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0601667\tvalid_1's multi_error: 0.128667\n",
      "[40]\ttraining's multi_error: 0.0248333\tvalid_1's multi_error: 0.125667\n",
      "[60]\ttraining's multi_error: 0.00641667\tvalid_1's multi_error: 0.129333\n",
      "[80]\ttraining's multi_error: 0.00133333\tvalid_1's multi_error: 0.126333\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's multi_error: 0.017\tvalid_1's multi_error: 0.124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.0615833\tvalid_1's multi_error: 0.125333\n",
      "[40]\ttraining's multi_error: 0.0249167\tvalid_1's multi_error: 0.123333\n",
      "[60]\ttraining's multi_error: 0.00616667\tvalid_1's multi_error: 0.122667\n",
      "[80]\ttraining's multi_error: 0.001\tvalid_1's multi_error: 0.123333\n",
      "[100]\ttraining's multi_error: 0.000333333\tvalid_1's multi_error: 0.121333\n",
      "Early stopping, best iteration is:\n",
      "[68]\ttraining's multi_error: 0.00308333\tvalid_1's multi_error: 0.120667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.06125\tvalid_1's multi_error: 0.127\n",
      "[40]\ttraining's multi_error: 0.0238333\tvalid_1's multi_error: 0.121667\n",
      "[60]\ttraining's multi_error: 0.00591667\tvalid_1's multi_error: 0.123667\n",
      "[80]\ttraining's multi_error: 0.00133333\tvalid_1's multi_error: 0.125\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's multi_error: 0.0238333\tvalid_1's multi_error: 0.121667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's multi_error: 0.059\tvalid_1's multi_error: 0.13\n",
      "[40]\ttraining's multi_error: 0.0235\tvalid_1's multi_error: 0.131\n",
      "[60]\ttraining's multi_error: 0.0055\tvalid_1's multi_error: 0.128333\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's multi_error: 0.0529167\tvalid_1's multi_error: 0.128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "357"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "imp = pd.DataFrame()\n",
    "imp['feat'] = used_feat\n",
    "\n",
    "params = {\n",
    "    'learning_rate': 0.1,\n",
    "    'metric': 'multi_error',\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 20,\n",
    "    'feature_fraction': 0.80,\n",
    "    'bagging_fraction': 0.75,\n",
    "    'bagging_freq': 2,\n",
    "    'n_jobs': 4,\n",
    "    'seed': 2020,\n",
    "    'max_depth': 10,\n",
    "    'num_leaves': 64,\n",
    "    'lambda_l1': 0.5,\n",
    "    'lambda_l2': 0.5,\n",
    "}\n",
    "\n",
    "oof_train = np.zeros((len(train_x), 20))\n",
    "preds = np.zeros((len(test_x), 20))\n",
    "folds = 5\n",
    "seeds = [44, 2020, 527, 1527]\n",
    "for seed in seeds:\n",
    "    kfold = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "    for fold, (trn_idx, val_idx) in enumerate(kfold.split(train_x, train_y)):\n",
    "        x_trn, y_trn, x_val, y_val = train_x.iloc[trn_idx], train_y.iloc[trn_idx], train_x.iloc[val_idx], train_y.iloc[val_idx]\n",
    "        train_set = lgb.Dataset(x_trn, y_trn)\n",
    "        val_set = lgb.Dataset(x_val, y_val)\n",
    "\n",
    "        model = lgb.train(params, train_set, num_boost_round=500000,\n",
    "                          valid_sets=(train_set, val_set), early_stopping_rounds=50,\n",
    "                          verbose_eval=20)\n",
    "        oof_train[val_idx] += model.predict(x_val) / len(seeds)\n",
    "        preds += model.predict(test_x) / folds / len(seeds)\n",
    "        scores.append(model.best_score['valid_1']['multi_error'])\n",
    "        imp['gain' + str(fold + 1)] = model.feature_importance(importance_type='gain')\n",
    "        imp['split' + str(fold + 1)] = model.feature_importance(importance_type='split')\n",
    "        del x_trn, y_trn, x_val, y_val, model, train_set, val_set\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat</th>\n",
       "      <th>gain</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>CNN_7</td>\n",
       "      <td>11983.911708</td>\n",
       "      <td>1819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>lgb_16</td>\n",
       "      <td>9953.930847</td>\n",
       "      <td>1484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>lgb_19</td>\n",
       "      <td>9375.355082</td>\n",
       "      <td>821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>CNN_5</td>\n",
       "      <td>8855.297567</td>\n",
       "      <td>1962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lgb_8</td>\n",
       "      <td>8771.549033</td>\n",
       "      <td>1482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>CNN_9</td>\n",
       "      <td>8037.791333</td>\n",
       "      <td>1628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lgb_12</td>\n",
       "      <td>7943.515531</td>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>CNN_11</td>\n",
       "      <td>7871.047307</td>\n",
       "      <td>1869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>lstm_19</td>\n",
       "      <td>7470.183928</td>\n",
       "      <td>1136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>lgb_17</td>\n",
       "      <td>7450.885394</td>\n",
       "      <td>1681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>CNN_2</td>\n",
       "      <td>7247.557231</td>\n",
       "      <td>1620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>lgb_15</td>\n",
       "      <td>6791.321268</td>\n",
       "      <td>1871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>CNN_14</td>\n",
       "      <td>6588.444252</td>\n",
       "      <td>1831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>lstm_18</td>\n",
       "      <td>6565.454937</td>\n",
       "      <td>2165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>CNN_0</td>\n",
       "      <td>6564.841809</td>\n",
       "      <td>1358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>lgb_18</td>\n",
       "      <td>6374.747565</td>\n",
       "      <td>1783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>CNN_12</td>\n",
       "      <td>5943.361991</td>\n",
       "      <td>2126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lgb_1</td>\n",
       "      <td>5925.189172</td>\n",
       "      <td>1637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>CNN_19</td>\n",
       "      <td>5415.002357</td>\n",
       "      <td>1037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>lgb_13</td>\n",
       "      <td>5150.781919</td>\n",
       "      <td>1668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>CNN_3</td>\n",
       "      <td>5098.879516</td>\n",
       "      <td>1691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lgb_6</td>\n",
       "      <td>5055.638984</td>\n",
       "      <td>1601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>lstm_4</td>\n",
       "      <td>5022.803235</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>lstm_13</td>\n",
       "      <td>5018.392167</td>\n",
       "      <td>1888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>CNN_4</td>\n",
       "      <td>4857.773213</td>\n",
       "      <td>1742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lgb_0</td>\n",
       "      <td>4500.791014</td>\n",
       "      <td>1245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>lstm_1</td>\n",
       "      <td>4361.098356</td>\n",
       "      <td>1949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lgb_5</td>\n",
       "      <td>3948.275343</td>\n",
       "      <td>1823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>lgb_14</td>\n",
       "      <td>3763.368428</td>\n",
       "      <td>1811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lgb_4</td>\n",
       "      <td>3409.307212</td>\n",
       "      <td>1639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>lstm_7</td>\n",
       "      <td>3373.396005</td>\n",
       "      <td>1814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lgb_3</td>\n",
       "      <td>3125.555446</td>\n",
       "      <td>1696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>CNN_10</td>\n",
       "      <td>3076.000550</td>\n",
       "      <td>1556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>lstm_12</td>\n",
       "      <td>2934.792443</td>\n",
       "      <td>2058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>lstm_0</td>\n",
       "      <td>2847.645235</td>\n",
       "      <td>1651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>CNN_15</td>\n",
       "      <td>2732.104073</td>\n",
       "      <td>1815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lgb_7</td>\n",
       "      <td>2628.252645</td>\n",
       "      <td>1494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>lstm_8</td>\n",
       "      <td>2607.640093</td>\n",
       "      <td>1930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lgb_2</td>\n",
       "      <td>2460.756097</td>\n",
       "      <td>1791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>lstm_3</td>\n",
       "      <td>2373.322172</td>\n",
       "      <td>1908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>lgb_10</td>\n",
       "      <td>2337.023476</td>\n",
       "      <td>1642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>CNN_6</td>\n",
       "      <td>2234.430806</td>\n",
       "      <td>1518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>CNN_16</td>\n",
       "      <td>2114.058902</td>\n",
       "      <td>1574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>lstm_17</td>\n",
       "      <td>2095.121784</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>CNN_8</td>\n",
       "      <td>2052.454216</td>\n",
       "      <td>1611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>lstm_5</td>\n",
       "      <td>1973.957457</td>\n",
       "      <td>2225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>lgb_9</td>\n",
       "      <td>1879.196677</td>\n",
       "      <td>1499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>CNN_13</td>\n",
       "      <td>1739.166806</td>\n",
       "      <td>1651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>lstm_11</td>\n",
       "      <td>1604.831848</td>\n",
       "      <td>2106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lgb_11</td>\n",
       "      <td>1600.943100</td>\n",
       "      <td>1692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>lstm_15</td>\n",
       "      <td>1418.508119</td>\n",
       "      <td>1938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>CNN_18</td>\n",
       "      <td>1061.071320</td>\n",
       "      <td>1899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>CNN_17</td>\n",
       "      <td>1024.297689</td>\n",
       "      <td>1579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>lstm_16</td>\n",
       "      <td>1021.189821</td>\n",
       "      <td>1775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>lstm_9</td>\n",
       "      <td>908.447881</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>CNN_1</td>\n",
       "      <td>907.237510</td>\n",
       "      <td>1537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>lstm_14</td>\n",
       "      <td>873.567421</td>\n",
       "      <td>2097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>lstm_6</td>\n",
       "      <td>840.595570</td>\n",
       "      <td>1825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>lstm_2</td>\n",
       "      <td>824.934767</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>lstm_10</td>\n",
       "      <td>693.842845</td>\n",
       "      <td>1806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>261.775196</td>\n",
       "      <td>1135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feat          gain  split\n",
       "48    CNN_7  11983.911708   1819\n",
       "17   lgb_16   9953.930847   1484\n",
       "20   lgb_19   9375.355082    821\n",
       "46    CNN_5   8855.297567   1962\n",
       "9     lgb_8   8771.549033   1482\n",
       "50    CNN_9   8037.791333   1628\n",
       "13   lgb_12   7943.515531   1984\n",
       "52   CNN_11   7871.047307   1869\n",
       "40  lstm_19   7470.183928   1136\n",
       "18   lgb_17   7450.885394   1681\n",
       "43    CNN_2   7247.557231   1620\n",
       "16   lgb_15   6791.321268   1871\n",
       "55   CNN_14   6588.444252   1831\n",
       "39  lstm_18   6565.454937   2165\n",
       "41    CNN_0   6564.841809   1358\n",
       "19   lgb_18   6374.747565   1783\n",
       "53   CNN_12   5943.361991   2126\n",
       "2     lgb_1   5925.189172   1637\n",
       "60   CNN_19   5415.002357   1037\n",
       "14   lgb_13   5150.781919   1668\n",
       "44    CNN_3   5098.879516   1691\n",
       "7     lgb_6   5055.638984   1601\n",
       "25   lstm_4   5022.803235   1980\n",
       "34  lstm_13   5018.392167   1888\n",
       "45    CNN_4   4857.773213   1742\n",
       "1     lgb_0   4500.791014   1245\n",
       "22   lstm_1   4361.098356   1949\n",
       "6     lgb_5   3948.275343   1823\n",
       "15   lgb_14   3763.368428   1811\n",
       "5     lgb_4   3409.307212   1639\n",
       "28   lstm_7   3373.396005   1814\n",
       "4     lgb_3   3125.555446   1696\n",
       "51   CNN_10   3076.000550   1556\n",
       "33  lstm_12   2934.792443   2058\n",
       "21   lstm_0   2847.645235   1651\n",
       "56   CNN_15   2732.104073   1815\n",
       "8     lgb_7   2628.252645   1494\n",
       "29   lstm_8   2607.640093   1930\n",
       "3     lgb_2   2460.756097   1791\n",
       "24   lstm_3   2373.322172   1908\n",
       "11   lgb_10   2337.023476   1642\n",
       "47    CNN_6   2234.430806   1518\n",
       "57   CNN_16   2114.058902   1574\n",
       "38  lstm_17   2095.121784   2024\n",
       "49    CNN_8   2052.454216   1611\n",
       "26   lstm_5   1973.957457   2225\n",
       "10    lgb_9   1879.196677   1499\n",
       "54   CNN_13   1739.166806   1651\n",
       "32  lstm_11   1604.831848   2106\n",
       "12   lgb_11   1600.943100   1692\n",
       "36  lstm_15   1418.508119   1938\n",
       "59   CNN_18   1061.071320   1899\n",
       "58   CNN_17   1024.297689   1579\n",
       "37  lstm_16   1021.189821   1775\n",
       "30   lstm_9    908.447881   1996\n",
       "42    CNN_1    907.237510   1537\n",
       "35  lstm_14    873.567421   2097\n",
       "27   lstm_6    840.595570   1825\n",
       "23   lstm_2    824.934767   1997\n",
       "31  lstm_10    693.842845   1806\n",
       "0     count    261.775196   1135"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat</th>\n",
       "      <th>gain</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>lstm_5</td>\n",
       "      <td>1973.957457</td>\n",
       "      <td>2225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>lstm_18</td>\n",
       "      <td>6565.454937</td>\n",
       "      <td>2165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>CNN_12</td>\n",
       "      <td>5943.361991</td>\n",
       "      <td>2126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>lstm_11</td>\n",
       "      <td>1604.831848</td>\n",
       "      <td>2106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>lstm_14</td>\n",
       "      <td>873.567421</td>\n",
       "      <td>2097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>lstm_12</td>\n",
       "      <td>2934.792443</td>\n",
       "      <td>2058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>lstm_17</td>\n",
       "      <td>2095.121784</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>lstm_2</td>\n",
       "      <td>824.934767</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>lstm_9</td>\n",
       "      <td>908.447881</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lgb_12</td>\n",
       "      <td>7943.515531</td>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>lstm_4</td>\n",
       "      <td>5022.803235</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>CNN_5</td>\n",
       "      <td>8855.297567</td>\n",
       "      <td>1962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>lstm_1</td>\n",
       "      <td>4361.098356</td>\n",
       "      <td>1949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>lstm_15</td>\n",
       "      <td>1418.508119</td>\n",
       "      <td>1938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>lstm_8</td>\n",
       "      <td>2607.640093</td>\n",
       "      <td>1930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>lstm_3</td>\n",
       "      <td>2373.322172</td>\n",
       "      <td>1908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>CNN_18</td>\n",
       "      <td>1061.071320</td>\n",
       "      <td>1899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>lstm_13</td>\n",
       "      <td>5018.392167</td>\n",
       "      <td>1888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>lgb_15</td>\n",
       "      <td>6791.321268</td>\n",
       "      <td>1871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>CNN_11</td>\n",
       "      <td>7871.047307</td>\n",
       "      <td>1869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>CNN_14</td>\n",
       "      <td>6588.444252</td>\n",
       "      <td>1831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>lstm_6</td>\n",
       "      <td>840.595570</td>\n",
       "      <td>1825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lgb_5</td>\n",
       "      <td>3948.275343</td>\n",
       "      <td>1823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>CNN_7</td>\n",
       "      <td>11983.911708</td>\n",
       "      <td>1819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>CNN_15</td>\n",
       "      <td>2732.104073</td>\n",
       "      <td>1815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>lstm_7</td>\n",
       "      <td>3373.396005</td>\n",
       "      <td>1814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>lgb_14</td>\n",
       "      <td>3763.368428</td>\n",
       "      <td>1811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>lstm_10</td>\n",
       "      <td>693.842845</td>\n",
       "      <td>1806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lgb_2</td>\n",
       "      <td>2460.756097</td>\n",
       "      <td>1791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>lgb_18</td>\n",
       "      <td>6374.747565</td>\n",
       "      <td>1783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>lstm_16</td>\n",
       "      <td>1021.189821</td>\n",
       "      <td>1775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>CNN_4</td>\n",
       "      <td>4857.773213</td>\n",
       "      <td>1742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lgb_3</td>\n",
       "      <td>3125.555446</td>\n",
       "      <td>1696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lgb_11</td>\n",
       "      <td>1600.943100</td>\n",
       "      <td>1692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>CNN_3</td>\n",
       "      <td>5098.879516</td>\n",
       "      <td>1691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>lgb_17</td>\n",
       "      <td>7450.885394</td>\n",
       "      <td>1681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>lgb_13</td>\n",
       "      <td>5150.781919</td>\n",
       "      <td>1668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>CNN_13</td>\n",
       "      <td>1739.166806</td>\n",
       "      <td>1651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>lstm_0</td>\n",
       "      <td>2847.645235</td>\n",
       "      <td>1651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>lgb_10</td>\n",
       "      <td>2337.023476</td>\n",
       "      <td>1642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lgb_4</td>\n",
       "      <td>3409.307212</td>\n",
       "      <td>1639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lgb_1</td>\n",
       "      <td>5925.189172</td>\n",
       "      <td>1637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>CNN_9</td>\n",
       "      <td>8037.791333</td>\n",
       "      <td>1628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>CNN_2</td>\n",
       "      <td>7247.557231</td>\n",
       "      <td>1620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>CNN_8</td>\n",
       "      <td>2052.454216</td>\n",
       "      <td>1611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lgb_6</td>\n",
       "      <td>5055.638984</td>\n",
       "      <td>1601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>CNN_17</td>\n",
       "      <td>1024.297689</td>\n",
       "      <td>1579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>CNN_16</td>\n",
       "      <td>2114.058902</td>\n",
       "      <td>1574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>CNN_10</td>\n",
       "      <td>3076.000550</td>\n",
       "      <td>1556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>CNN_1</td>\n",
       "      <td>907.237510</td>\n",
       "      <td>1537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>CNN_6</td>\n",
       "      <td>2234.430806</td>\n",
       "      <td>1518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>lgb_9</td>\n",
       "      <td>1879.196677</td>\n",
       "      <td>1499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lgb_7</td>\n",
       "      <td>2628.252645</td>\n",
       "      <td>1494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>lgb_16</td>\n",
       "      <td>9953.930847</td>\n",
       "      <td>1484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lgb_8</td>\n",
       "      <td>8771.549033</td>\n",
       "      <td>1482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>CNN_0</td>\n",
       "      <td>6564.841809</td>\n",
       "      <td>1358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lgb_0</td>\n",
       "      <td>4500.791014</td>\n",
       "      <td>1245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>lstm_19</td>\n",
       "      <td>7470.183928</td>\n",
       "      <td>1136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>261.775196</td>\n",
       "      <td>1135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>CNN_19</td>\n",
       "      <td>5415.002357</td>\n",
       "      <td>1037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>lgb_19</td>\n",
       "      <td>9375.355082</td>\n",
       "      <td>821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feat          gain  split\n",
       "26   lstm_5   1973.957457   2225\n",
       "39  lstm_18   6565.454937   2165\n",
       "53   CNN_12   5943.361991   2126\n",
       "32  lstm_11   1604.831848   2106\n",
       "35  lstm_14    873.567421   2097\n",
       "33  lstm_12   2934.792443   2058\n",
       "38  lstm_17   2095.121784   2024\n",
       "23   lstm_2    824.934767   1997\n",
       "30   lstm_9    908.447881   1996\n",
       "13   lgb_12   7943.515531   1984\n",
       "25   lstm_4   5022.803235   1980\n",
       "46    CNN_5   8855.297567   1962\n",
       "22   lstm_1   4361.098356   1949\n",
       "36  lstm_15   1418.508119   1938\n",
       "29   lstm_8   2607.640093   1930\n",
       "24   lstm_3   2373.322172   1908\n",
       "59   CNN_18   1061.071320   1899\n",
       "34  lstm_13   5018.392167   1888\n",
       "16   lgb_15   6791.321268   1871\n",
       "52   CNN_11   7871.047307   1869\n",
       "55   CNN_14   6588.444252   1831\n",
       "27   lstm_6    840.595570   1825\n",
       "6     lgb_5   3948.275343   1823\n",
       "48    CNN_7  11983.911708   1819\n",
       "56   CNN_15   2732.104073   1815\n",
       "28   lstm_7   3373.396005   1814\n",
       "15   lgb_14   3763.368428   1811\n",
       "31  lstm_10    693.842845   1806\n",
       "3     lgb_2   2460.756097   1791\n",
       "19   lgb_18   6374.747565   1783\n",
       "37  lstm_16   1021.189821   1775\n",
       "45    CNN_4   4857.773213   1742\n",
       "4     lgb_3   3125.555446   1696\n",
       "12   lgb_11   1600.943100   1692\n",
       "44    CNN_3   5098.879516   1691\n",
       "18   lgb_17   7450.885394   1681\n",
       "14   lgb_13   5150.781919   1668\n",
       "54   CNN_13   1739.166806   1651\n",
       "21   lstm_0   2847.645235   1651\n",
       "11   lgb_10   2337.023476   1642\n",
       "5     lgb_4   3409.307212   1639\n",
       "2     lgb_1   5925.189172   1637\n",
       "50    CNN_9   8037.791333   1628\n",
       "43    CNN_2   7247.557231   1620\n",
       "49    CNN_8   2052.454216   1611\n",
       "7     lgb_6   5055.638984   1601\n",
       "58   CNN_17   1024.297689   1579\n",
       "57   CNN_16   2114.058902   1574\n",
       "51   CNN_10   3076.000550   1556\n",
       "42    CNN_1    907.237510   1537\n",
       "47    CNN_6   2234.430806   1518\n",
       "10    lgb_9   1879.196677   1499\n",
       "8     lgb_7   2628.252645   1494\n",
       "17   lgb_16   9953.930847   1484\n",
       "9     lgb_8   8771.549033   1482\n",
       "41    CNN_0   6564.841809   1358\n",
       "1     lgb_0   4500.791014   1245\n",
       "40  lstm_19   7470.183928   1136\n",
       "0     count    261.775196   1135\n",
       "60   CNN_19   5415.002357   1037\n",
       "20   lgb_19   9375.355082    821"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp['gain'] = imp[[f for f in imp.columns if 'gain' in f]].sum(axis=1)/folds\n",
    "imp['split'] = imp[[f for f in imp.columns if 'split' in f]].sum(axis=1)\n",
    "imp = imp.sort_values(by=['gain'], ascending=False)\n",
    "imp[['feat', 'gain', 'split']]\n",
    "imp = imp.sort_values(by=['split'], ascending=False)\n",
    "imp[['feat', 'gain', 'split']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_combo(y, y_pred):\n",
    "    # ID\n",
    "    mapping = {\n",
    "        '0': 'A_1', '1': 'B_2', '2': 'A_3', '3': 'A_4', '4': 'B_3', '5': 'C_5', '6': 'C_2', '7': 'A_5', '8': 'B_1', \n",
    "        '9': 'C_1', '10': 'A_2', '11': 'C_3', '12': 'B_5', '13': 'B_4', '14': 'C_4', \n",
    "        '15': 'D_6', '16': 'E_7', '17': 'F_8', '18': 'G_9', '19': 'H_0'\n",
    "              }\n",
    "    # ID\n",
    "    code_y, code_y_pred = mapping[str(int(y))], mapping[str(int(y_pred))]\n",
    "    if code_y == code_y_pred: #1.0\n",
    "        return 1.0\n",
    "    elif code_y.split(\"_\")[0] == code_y_pred.split(\"_\")[0]: #1.0/7\n",
    "        return 1.0/7\n",
    "    elif code_y.split(\"_\")[1] == code_y_pred.split(\"_\")[1]: #1.0/3\n",
    "        return 1.0/3\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8762\n",
      "0.89228\n"
     ]
    }
   ],
   "source": [
    "labels = np.argmax(preds, axis=1)\n",
    "oof_y = np.argmax(oof_train, axis=1)\n",
    "print(round(accuracy_score(train_y, oof_y), 5))\n",
    "score = sum(acc_combo(y_true, y_pred) for y_true, y_pred in zip(train_y, oof_y)) / oof_y.shape[0]\n",
    "print(round(score, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f244047b290>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD4CAYAAADsKpHdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAZvUlEQVR4nO3df5BV9Znn8fcnYAyaqKiNg924OJFkgtQGA8uya8ZxJBXRZEUTnLSVUWZDliyFu5rN7IxOUjOmZqjSTNQpZyKzGByR+AMWdSSOJBKNk0kVQhqDAqKxMxJpIUCiMWSnJAGf/eM8XXVpLrfvOd3QF/i8qm7dc597nm9/T3O7P/f8uI0iAjMzs3cM9QTMzKw1OBDMzAxwIJiZWXIgmJkZ4EAwM7M0fKgnUNXpp58eY8eOHeppmJkdUdatW/eziGir99wRGwhjx46lq6trqKdhZnZEkfSTgz3nQ0ZmZgY4EMzMLDkQzMwMcCCYmVlyIJiZGeBAMDOz5EAwMzPAgWBmZsmBYGZmwBH8SWUzs2PVzr97onTPqGs/2u863kMwMzPAgWBmZsmBYGZmgAPBzMySA8HMzIAmAkHSuyStlfScpE2Svpz1myS9Jml93i6t6blRUreklyRdXFOfJGlDPneHJGX9eElLs75G0tjB31QzM2ukmctO9wAXRcSvJB0HfF/Synzu9oj4au3KksYDncC5wJnAdyS9LyL2AQuAOcAzwOPAdGAlMBt4IyLOkdQJ3AJ8auCbZ2ZXPPT90j2PfPLDh2Am1ur63UOIwq/y4XF5iwYtM4AHI2JPRLwCdANTJI0GToqI1RERwL3A5TU9i3N5OTCtd+/BzMwOj6bOIUgaJmk9sBNYFRFr8qlrJT0v6W5JI7PWDmytae/JWnsu963v1xMRe4E3gdPqzGOOpC5JXbt27WpqA83MrDlNBUJE7IuIiUAHxbv9CRSHf94LTAS2A7fm6vXe2UeDeqOevvNYGBGTI2JyW1vd/yPazMwqKnWVUUT8AngamB4ROzIo3gbuAqbkaj3AmJq2DmBb1jvq1PfrkTQcOBl4vdSWmJnZgDRzlVGbpFNyeQTwEeDFPCfQ6wpgYy6vADrzyqGzgXHA2ojYDuyWNDXPD1wDPFrTMyuXZwJP5XkGMzM7TJq5ymg0sFjSMIoAWRYRj0laImkixaGdLcDnACJik6RlwAvAXmBeXmEEMBe4BxhBcXVR79VKi4Alkrop9gw6B2HbzMyshH4DISKeB86rU7+6Qc98YH6dehcwoU79LeDK/uZiZmaHjj+pbGZmgAPBzMyS/4McazmXPPrJ0j0rZzx0CGZidmzxHoKZmQEOBDMzSw4EMzMDHAhmZpYcCGZmBjgQzMwsORDMzAxwIJiZWXIgmJkZ4EAwM7PkQDAzM8CBYGZmyYFgZmaAA8HMzJIDwczMAAeCmZmlfgNB0rskrZX0nKRNkr6c9VMlrZL0ct6PrOm5UVK3pJckXVxTnyRpQz53hyRl/XhJS7O+RtLYwd9UMzNrpJk9hD3ARRHxQWAiMF3SVOAG4MmIGAc8mY+RNB7oBM4FpgN3ShqWYy0A5gDj8jY967OBNyLiHOB24JZB2DYzMyuh30CIwq/y4XF5C2AGsDjri4HLc3kG8GBE7ImIV4BuYIqk0cBJEbE6IgK4t09P71jLgWm9ew9mZnZ4NHUOQdIwSeuBncCqiFgDnBER2wHyflSu3g5srWnvyVp7Lvet79cTEXuBN4HT6sxjjqQuSV27du1qbgvNzKwpTQVCROyLiIlAB8W7/QkNVq/3zj4a1Bv19J3HwoiYHBGT29ra+pu2mZmVUOoqo4j4BfA0xbH/HXkYiLzfmav1AGNq2jqAbVnvqFPfr0fScOBk4PUyczMzs4Fp5iqjNkmn5PII4CPAi8AKYFauNgt4NJdXAJ155dDZFCeP1+Zhpd2Spub5gWv69PSONRN4Ks8zmJnZYTK8iXVGA4vzSqF3AMsi4jFJq4FlkmYDrwJXAkTEJknLgBeAvcC8iNiXY80F7gFGACvzBrAIWCKpm2LPoHMwNs7MzJrXbyBExPPAeXXqPwemHaRnPjC/Tr0LOOD8Q0S8RQaKmZkNDX9S2czMAAeCmZklB4KZmQHNnVS2Y8T/WXJx/yvV8bmrvz3IMzGzoeA9BDMzAxwIZmaWHAhmZgY4EMzMLDkQzMwMcCCYmVlyIJiZGeBAMDOz5EAwMzPAgWBmZsmBYGZmgAPBzMySA8HMzAAHgpmZJQeCmZkBDgQzM0v9BoKkMZK+K2mzpE2Srsv6TZJek7Q+b5fW9NwoqVvSS5IurqlPkrQhn7tDkrJ+vKSlWV8jaezgb6qZmTXSzB7CXuALEfEBYCowT9L4fO72iJiYt8cB8rlO4FxgOnCnpGG5/gJgDjAub9OzPht4IyLOAW4Hbhn4ppmZWRn9BkJEbI+IZ3N5N7AZaG/QMgN4MCL2RMQrQDcwRdJo4KSIWB0RAdwLXF7TsziXlwPTevcezMzs8Ch1DiEP5ZwHrMnStZKel3S3pJFZawe21rT1ZK09l/vW9+uJiL3Am8Bpdb7+HEldkrp27dpVZupmZtaPpgNB0ruBh4DrI+KXFId/3gtMBLYDt/auWqc9GtQb9exfiFgYEZMjYnJbW1uzUzczsyY0FQiSjqMIg/si4mGAiNgREfsi4m3gLmBKrt4DjKlp7wC2Zb2jTn2/HknDgZOB16tskJmZVdPMVUYCFgGbI+K2mvromtWuADbm8gqgM68cOpvi5PHaiNgO7JY0Nce8Bni0pmdWLs8EnsrzDGZmdpgMb2Kd84GrgQ2S1mftz4CrJE2kOLSzBfgcQERskrQMeIHiCqV5EbEv++YC9wAjgJV5gyJwlkjqptgz6BzYZpmZWVn9BkJEfJ/6x/gfb9AzH5hfp94FTKhTfwu4sr+5mJnZoeNPKpuZGeBAMDOz5EAwMzPAgWBmZsmBYGZmgAPBzMySA8HMzAAHgpmZJQeCmZkBDgQzM0sOBDMzAxwIZmaWHAhmZgY4EMzMLDkQzMwMaO4/yLEjxPJ/mF66Z+Z//dYhmImZHYmO+EDYteAbpXva5v7hIZiJmdmRzYeMzMwMcCCYmVnqNxAkjZH0XUmbJW2SdF3WT5W0StLLeT+ypudGSd2SXpJ0cU19kqQN+dwdkpT14yUtzfoaSWMHf1PNzKyRZs4h7AW+EBHPSnoPsE7SKuCPgCcj4mZJNwA3AH8qaTzQCZwLnAl8R9L7ImIfsACYAzwDPA5MB1YCs4E3IuIcSZ3ALcCnBnND7dhy6SN/Vbrn8Su+dAhmYnbk6HcPISK2R8Szubwb2Ay0AzOAxbnaYuDyXJ4BPBgReyLiFaAbmCJpNHBSRKyOiADu7dPTO9ZyYFrv3oOZmR0epc4h5KGc84A1wBkRsR2K0ABG5WrtwNaatp6stedy3/p+PRGxF3gTOK3O158jqUtS165du8pM3czM+tH0ZaeS3g08BFwfEb9s8Aa+3hPRoN6oZ/9CxEJgIcDkyZMPeN7MrNXt+Jt1pXvOuH7SIZjJgZoKBEnHUYTBfRHxcJZ3SBodEdvzcNDOrPcAY2raO4BtWe+oU6/t6ZE0HDgZeL3C9pjZIPvUw92V+pZ+4pxBnokdas1cZSRgEbA5Im6reWoFMCuXZwGP1tQ788qhs4FxwNo8rLRb0tQc85o+Pb1jzQSeyvMMZmZ2mDSzh3A+cDWwQdL6rP0ZcDOwTNJs4FXgSoCI2CRpGfACxRVK8/IKI4C5wD3ACIqri1ZmfRGwRFI3xZ5B5wC3y8zMSuo3ECLi+9Q/xg8w7SA984H5depdwIQ69bfIQDEzs6HhTyqbmRngQDAzs+RAMDMzwIFgZmbpiP//EMzMmvXDr+/sf6U+zvvsqP5XOkp4D8HMzADvIZjZEWLl0p+V7rnkU6cfgpkcvbyHYGZmgAPBzMySA8HMzAAHgpmZJQeCmZkBDgQzM0u+7NSshV22/Jule1bM/C+HYCYD87VHdlTqm3fFGYM8E2vEewhmZgY4EMzMLDkQzMwMcCCYmVlyIJiZGdBEIEi6W9JOSRtrajdJek3S+rxdWvPcjZK6Jb0k6eKa+iRJG/K5OyQp68dLWpr1NZLGDu4mmplZM5rZQ7gHmF6nfntETMzb4wCSxgOdwLnZc6ekYbn+AmAOMC5vvWPOBt6IiHOA24FbKm6LmZkNQL+fQ4iI75V41z4DeDAi9gCvSOoGpkjaApwUEasBJN0LXA6szJ6bsn858HeSFBFRYjsq++mCv6rU91tzvzTIMzEzG1oD+WDatZKuAbqAL0TEG0A78EzNOj1Z+00u962T91sBImKvpDeB04AD/vi5pDkUexmcddZZA5h663n6ro+V7rnwv/3TIZiJmR2rqp5UXgC8F5gIbAduzbrqrBsN6o16DixGLIyIyRExua2trdyMzcysoUqBEBE7ImJfRLwN3AVMyad6gDE1q3YA27LeUae+X4+k4cDJwOtV5mVmZtVVOmQkaXREbM+HVwC9VyCtAO6XdBtwJsXJ47URsU/SbklTgTXANcDf1vTMAlYDM4GnDtf5g8Hy4tdmVOr7nXmPDvJMzMyq6zcQJD0AXAicLqkH+AvgQkkTKQ7tbAE+BxARmyQtA14A9gLzImJfDjWX4oqlERQnk1dmfRGwJE9Av05xlZLZkPrYwwsq9f3TJ+YO8kzMDp9mrjK6qk55UYP15wPz69S7gAl16m8BV/Y3DzMzO7T8SWUzMwMcCGZmlhwIZmYGOBDMzCw5EMzMDHAgmJlZciCYmRngQDAzs+RAMDMzwIFgZmbJgWBmZoADwczM0kD+xzQzs2PK9q+8Vqlv9J+0979SC/AegpmZAQ4EMzNLDgQzMwMcCGZmlhwIZmYGOBDMzCz1GwiS7pa0U9LGmtqpklZJejnvR9Y8d6OkbkkvSbq4pj5J0oZ87g5JyvrxkpZmfY2ksYO7iWZm1oxm9hDuAab3qd0APBkR44An8zGSxgOdwLnZc6ekYdmzAJgDjMtb75izgTci4hzgduCWqhtjZmbV9RsIEfE94PU+5RnA4lxeDFxeU38wIvZExCtANzBF0mjgpIhYHREB3Nunp3es5cC03r0HMzM7fKqeQzgjIrYD5P2orLcDW2vW68laey73re/XExF7gTeB0+p9UUlzJHVJ6tq1a1fFqZuZWT2DfVK53jv7aFBv1HNgMWJhREyOiMltbW0Vp2hmZvVUDYQdeRiIvN+Z9R5gTM16HcC2rHfUqe/XI2k4cDIHHqIyM7NDrOoft1sBzAJuzvtHa+r3S7oNOJPi5PHaiNgnabekqcAa4Brgb/uMtRqYCTyV5xnsCHTTsov7X6le3x98e5BnYmZl9RsIkh4ALgROl9QD/AVFECyTNBt4FbgSICI2SVoGvADsBeZFxL4cai7FFUsjgJV5A1gELJHUTbFn0DkoW2ZmZqX0GwgRcdVBnpp2kPXnA/Pr1LuACXXqb5GBYmZmQ8efVDYzM8CBYGZmyYFgZmaAA8HMzJIDwczMAAeCmZklB4KZmQEOBDMzSw4EMzMDHAhmZpYcCGZmBjgQzMwsORDMzAxwIJiZWXIgmJkZ4EAwM7NU9b/QNLN+fHz5fZX6Hpv56UGeiVlzvIdgZmaAA8HMzNKAAkHSFkkbJK2X1JW1UyWtkvRy3o+sWf9GSd2SXpJ0cU19Uo7TLekOSRrIvMzMrLzB2EP4/YiYGBGT8/ENwJMRMQ54Mh8jaTzQCZwLTAfulDQsexYAc4BxeZs+CPMyM7MSDsUhoxnA4lxeDFxeU38wIvZExCtANzBF0mjgpIhYHREB3FvTY2Zmh8lAAyGAJyStkzQna2dExHaAvB+V9XZga01vT9bac7lv3czMDqOBXnZ6fkRskzQKWCXpxQbr1jsvEA3qBw5QhM4cgLPOOqvsXM3MrIEB7SFExLa83wk8AkwBduRhIPJ+Z67eA4ypae8AtmW9o0693tdbGBGTI2JyW1vbQKZuZmZ9VA4ESSdKek/vMvBRYCOwApiVq80CHs3lFUCnpOMlnU1x8nhtHlbaLWlqXl10TU2PmZkdJgM5ZHQG8EheITocuD8iviXpB8AySbOBV4ErASJik6RlwAvAXmBeROzLseYC9wAjgJV5MzOzw6hyIETEvwIfrFP/OTDtID3zgfl16l3AhKpzMTOzgfMnlc3MDHAgmJlZciCYmRngQDAzs+RAMDMzwIFgZmbJgWBmZoADwczMkgPBzMwAB4KZmSUHgpmZAQ4EMzNLDgQzMwMcCGZmlhwIZmYGOBDMzCw5EMzMDHAgmJlZciCYmRngQDAzs9QygSBpuqSXJHVLumGo52NmdqxpiUCQNAz4GnAJMB64StL4oZ2VmdmxpSUCAZgCdEfEv0bEr4EHgRlDPCczs2OKImKo54CkmcD0iPhsPr4a+I8RcW2f9eYAc/Lh+4GXGgx7OvCzAU7taBmjFebQKmO0whxaZYxWmEOrjNEKczhcY/y7iGir98TwAX7hwaI6tQOSKiIWAgubGlDqiojJA5rUUTJGK8yhVcZohTm0yhitMIdWGaMV5tAKY7TKIaMeYEzN4w5g2xDNxczsmNQqgfADYJyksyW9E+gEVgzxnMzMjiktccgoIvZKuhb4NjAMuDsiNg1w2KYOLR0jY7TCHFpljFaYQ6uM0QpzaJUxWmEOQz5GS5xUNjOzodcqh4zMzGyIORDMzAw4SgNhoH8GQ9LdknZK2ljx64+R9F1JmyVtknRdhTHeJWmtpOdyjC9XmUuONUzSDyU9VrF/i6QNktZL6qrQf4qk5ZJezO/JfyrZ//782r23X0q6vsI8Pp/fy42SHpD0rgpjXJf9m5qdQ73Xk6RTJa2S9HLejyzZf2XO4W1J/V5ieJAx/jr/TZ6X9IikUyqM8ZfZv17SE5LOLDtGzXN/LCkknV5yDjdJeq3m9XFplTlI+h/5e2OTpK+UHUPS0po5bJG0vsIYEyU90/uzJmlKyf4PSlqdP6/flHRSozkcICKOqhvFSekfA78NvBN4DhhfcowLgA8BGyvOYTTwoVx+D/CjCnMQ8O5cPg5YA0ytOJ//BdwPPFaxfwtw+gD+TRYDn83ldwKnDPDf96cUH64p09cOvAKMyMfLgD8qOcYEYCNwAsUFGd8BxlV5PQFfAW7I5RuAW0r2f4Diw5lPA5MrzuGjwPBcvqXRHBqMcVLN8v8E/r7sGFkfQ3FRyU8avdYOMoebgD8u8e9Yb4zfz3/P4/PxqCrbUfP8rcCfV5jHE8AluXwp8HTJ/h8Av5fLnwH+ssxr/GjcQxjwn8GIiO8Br1edQERsj4hnc3k3sJniF1KZMSIifpUPj8tb6SsAJHUAHwO+XrZ3MOQ7lAuARQAR8euI+MUAhpwG/DgiflKhdzgwQtJwil/qZT/r8gHgmYj4t4jYC/wzcEV/TQd5Pc2gCEry/vIy/RGxOSIafVK/mTGeyO0AeIbi8z9lx/hlzcMT6ec12uBn63bgTwbQ37SDjDEXuDki9uQ6O6vOQ5KAPwAeqDBGAL3v6k+mwWv0IP3vB76Xy6uATzaaQ19HYyC0A1trHvdQ8pfxYJI0FjiP4h1+2d5hudu5E1gVEaXHAP6G4gft7Qq9vQJ4QtI6FX8+pIzfBnYB/5CHrb4u6cQBzKWTfn7Q6omI14CvAq8C24E3I+KJksNsBC6QdJqkEyjewY3pp+dgzoiI7Tm37cCoiuMMls8AK6s0SpovaSvwaeDPK/RfBrwWEc9V+frp2jx0dXejw28NvA/4XUlrJP2zpP8wgLn8LrAjIl6u0Hs98Nf5/fwqcGPJ/o3AZbl8JSVfn0djIDT1ZzAOB0nvBh4Cru/zTqopEbEvIiZSvHObImlCya//cWBnRKwr+7X7OD8iPkTx12jnSbqgRO9wit3aBRFxHvD/KA6RlKbiQ4uXAf+3Qu9IinflZwNnAidK+sMyY0TEZopDK6uAb1EcjtzbsOkIIOmLFNtxX5X+iPhiRIzJ/mv7W7/P1z4B+CIVgqTGAuC9wESKsL+1whjDgZHAVOB/A8vynX4VV1HhTUuaC3w+v5+fJ/esS/gMxc/oOorD1b8u03w0BkJL/BkMScdRhMF9EfHwQMbKQyxPA9NLtp4PXCZpC8Whs4skfaPC19+W9zuBRygOyzWrB+ip2btZThEQVVwCPBsROyr0fgR4JSJ2RcRvgIeB/1x2kIhYFBEfiogLKHbXq7wLBNghaTRA3jc8RHGoSJoFfBz4dOSB5wG4n5KHKCh+kZ8NPJev0w7gWUm/1ewAEbEj3zy9DdxFuddnrx7g4TxUu5Zij/qgJ7cPJg9HfgJYWmEOALMoXptQvPEptS0R8WJEfDQiJlGE0o/L9B+NgTDkfwYj31ksAjZHxG0Vx2jrvepD0giKX2gvlhkjIm6MiI6IGEvxfXgqIkq9K5Z0oqT39C5TnIhs+uqriPgpsFXS+7M0DXihzBxqDOSd16vAVEkn5L/PNIpzO6VIGpX3Z1H84FedzwqKH37y/tGK41QmaTrwp8BlEfFvFccYV/PwMsq/RjdExKiIGJuv0x6KCzJ+WmIOo2seXkGJ12eNfwQuyvHeR3HxQ5W/OvoR4MWI6KnQC8Wb19/L5Yso+Yaj5vX5DuBLwN+X+uplzkAfKTeKY7s/okjHL1bof4Bi1/M3FC/Q2SX7P0xxmOp5YH3eLi05xr8HfphjbKSfKxaaGO9CKlxlRHEO4Lm8bar4/ZwIdOW2/CMwssIYJwA/B04ewPfgyxS/sDYCS8grSkqO8S8UgfYcMK3q6wk4DXiS4gf+SeDUkv1X5PIeYAfw7Qpz6KY439b7Gu3vCqF6YzyU38/ngW8C7WXH6PP8FhpfZVRvDkuADTmHFcDoCtvxTuAbuS3PAhdV2Q7gHuC/D+B18WFgXb6+1gCTSvZfR/G770fAzeRfo2j25j9dYWZmwNF5yMjMzCpwIJiZGeBAMDOz5EAwMzPAgWBmZsmBYGZmgAPBzMzS/wccP5oS0txFAAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f240ba67050>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub = pd.read_csv(root_path+'submit_example.csv')\n",
    "\n",
    "sub['behavior_id'] = labels\n",
    "\n",
    "vc = data_train['behavior_id'].value_counts().sort_index()\n",
    "sns.barplot(vc.index, vc.values)\n",
    "plt.show()\n",
    "vc = sub['behavior_id'].value_counts().sort_index()\n",
    "sns.barplot(vc.index, vc.values)\n",
    "plt.show()\n",
    "sub.to_csv('emsemble%.5f.csv' % score, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
